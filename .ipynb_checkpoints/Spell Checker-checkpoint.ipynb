{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6fdd43-f01c-4a3e-a2b5-71f749b50282",
   "metadata": {},
   "source": [
    "The aim of this project is to build an NLP model that detects wrongly spelled words, provide the correct word suggestions for the wrongly spelled words, get the probability of occurence of the word and use algorithms to implement autocorrect functionality.\n",
    "\n",
    "Errors for Spell Checkers\n",
    "Typographical errors: erorrs that occur as a result of human imperfection while operating the keyboard such as insertiom, deletion, replacement or swapping of characters e.g spelling errors, words with recurring characters between them .\n",
    "\n",
    "cognitive Terms: like phonetic or grammatical error.\n",
    "\n",
    "The steps involved in bulding this model will be \n",
    "\n",
    "1. Data Collection\r\n",
    "   * \n",
    "Corpus Creation: Gather a large corpus of correctly spelled text. This can be from books, articles, or any other reliable sources.\n",
    "    * \r\n",
    "Error Data: Collect or generate data with common spelling errors. This can be done by introducing typical typos or using datasets with annotated spelling mistakes\n",
    "3.\n",
    "2. Preprocessi\n",
    "    * ng\r\n",
    "Tokenization: Break down the text into individual words or toke\n",
    "   * ns.\r\n",
    "Normalization: Convert all text to a standard format, such as lowercasing all words and removing punctuat\n",
    "4. Error Detection\r\n",
    "    * \n",
    "Dictionary Lookup: Use a dictionary to check if a word exists. If not, itâ€™s flagged as a potential error.\n",
    "    * \r\n",
    "Language Models: Employ language models to identify contextually incorrect words that might be real words but used incorrectly\n",
    "5\r\n",
    "4. Error Correct \n",
    "    * on\r\n",
    "Edit Distance: Calculate the minimum number of operations (insertions, deletions, substitutions) required to transform the misspelled word into a valid word. The Levenshtein distance is commonly used for thi\n",
    "     * s1.\r\n",
    "Phonetic Algorithms: Use phonetic algorithms like Soundex or Metaphone to suggest corrections based on how words so\n",
    "    * und.\r\n",
    "Contextual Correction: Use language models (e.g., n-grams, neural networks) to suggest corrections based on the context of the surrounding w7r s.\r\n",
    "5. Candidate Gene\n",
    "    * ration\r\n",
    "Generate Suggestions: For each detected error, generate a list of possible corrections using the methods\n",
    "    *  above.\r\n",
    "Ranking: Rank the suggestions based on their likelihood. This can be done using frequency counts from the corpus or probabilities from a langua\n",
    "\n",
    "8. Evaluation\r\n",
    "   * \n",
    "Accuracy Testing: Test the spell checker on a separate dataset to evaluate its accuracy in detecting and correcting errors.\n",
    "   * \r\n",
    "User Feedback: Incorporate user feedback to improve the system over time\n",
    "9\r\n",
    "7. Implementati\n",
    "   * on\r\n",
    "Integration: Integrate the spell checker into applications like word processors, search engines, or chatbo\n",
    "   * ts.\r\n",
    "User Interface: Design a user-friendly interface that highlights errors and suggests correcti\n",
    "\n",
    "* ons.\r\n",
    "Example Libraries and\n",
    "* Tools\r\n",
    "NLTK: Provides tools for tokenization, normalization, and basic spell ch\n",
    "* cking.\r\n",
    "TextBlob: Simplifies many NLP tasks, including spell ch* ecking.\r\n",
    "Hunspell: A popular spell checker used in many appli* cations.\r\n",
    "Neuspell: A neural spelling correction toolkit that leverages deep learning2ge model.a dicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad20819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary Libraries and modules\n",
    "\n",
    "import os, sys, gc, warnings\n",
    "import logging, math, re, heapq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from IPython.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from nltk.tokenize  import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7860f704-26ee-4d3c-a050-61f1791e5451",
   "metadata": {},
   "source": [
    "The above Libraries are imported and they mean\n",
    "\n",
    "os: Interacts with the operating system (e.g., file and directory operations).\n",
    "\n",
    "sys: Provides access to system-specific parameters and functions.\n",
    "\n",
    "gc: Interfaces with the garbage collector to manage memory.\n",
    "\n",
    "warnings: Manages warning messages.\n",
    "\n",
    "logging: Provides a flexible framework for emitting log messages.\n",
    "\n",
    "math: Offers mathematical functions.\n",
    "\n",
    "re: Handles regular expressions\n",
    "\n",
    "heapq: Implements a heap queue algorithm, also known as the priority queue algorithm.\n",
    "\n",
    "Counter: A dict subclass for counting hashable objects.\r\n",
    "\n",
    "display: A function to display rich content (e.g., HTML, images) in Jupyter notebooks.\n",
    "\r\n",
    "HTML: A function to display HTML content in Jupyter notebooks\n",
    ".\r\n",
    "InteractiveShell: Configures the interactive shell environment in Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab567aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>  div#notebook-container{width:95%;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "#pd.set_option('max_rows', None)\n",
    "#pd.set_option('max_columns', None)\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "display(HTML(data = \"\"\"<style>  div#notebook-container{width:95%;}</style>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621eaf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93780b55-3a09-4698-a417-3f1077ab2ab6",
   "metadata": {},
   "source": [
    "Stopwords are words that do not convey significant meaning in a text e.g as, in, the, of, is etc.\n",
    "So the above code downloads such words so that we can focus on the more meaningful words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d45504ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = 't8.shakespeare.txt' # assigning a variable for the Location(path) of the file containing text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c64ec-478b-4220-bca1-a4ba03b9a467",
   "metadata": {},
   "source": [
    "DATA PROCESSING:The steps involved are\n",
    "\n",
    "1. Lexical Processing: these include\n",
    "\n",
    "    *Tokenization: The process of breaking down text into smaller units called tokens. This is usually the first step. these toens may be words phrases or characters and they are stored in a list.\n",
    "   \n",
    "   * Stopword removal\n",
    "\n",
    "    * Stemming: This involves reducing words to their base form. It deal with removal of prefixes and/or suffixes to get root word e.g (processing --> process)\n",
    "\n",
    "    * Lemmatization: similar to stemminng but converts the word toa meaningful base form\n",
    "\n",
    "    * TF-IDF(Ter Frequency-Inverse Document Frequency): statistical measures the importance of a word in a document relative to a collection of documnets(corpus)\n",
    "\n",
    "\n",
    "2. Syntactic processing\n",
    "    * Part of Speech(POS) Tagging: Labelling each word in a sentence with its part of speech.\n",
    "    * Named Entity Recognition(NER): process of identifying and classifting named entities into predefined categories e.g Samuel(Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ede2c81-afad-4e31-b337-544560da078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_list = [] #stores the words extracted from the file in a list\n",
    "\n",
    "# open the file in file_location in read mode\n",
    "with open(file_location, \"r\") as file:\n",
    "    #read the file\n",
    "    file_read = file.read()\n",
    "    # find all characters in file_read and extract them to preproces_file\n",
    "    preprocess_file = re.findall(r\"\\w+\", file_read)  # Extract words from the file\n",
    "    \n",
    "    for word in preprocess_file:  # Iterate through the words found\n",
    "        word_list.append(word.lower())  # Append each word in lowercase to word_list\n",
    "\n",
    "vocab = set(word_list)  # Create a set of unique words (vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b57158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'the',\n",
       " '100th',\n",
       " 'etext',\n",
       " 'file',\n",
       " 'presented',\n",
       " 'by',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'and',\n",
       " 'is',\n",
       " 'presented',\n",
       " 'in',\n",
       " 'cooperation',\n",
       " 'with',\n",
       " 'world',\n",
       " 'library',\n",
       " 'inc',\n",
       " 'from',\n",
       " 'their',\n",
       " 'library',\n",
       " 'of',\n",
       " 'the',\n",
       " 'future',\n",
       " 'and',\n",
       " 'shakespeare',\n",
       " 'cdroms',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'often',\n",
       " 'releases',\n",
       " 'etexts',\n",
       " 'that',\n",
       " 'are',\n",
       " 'not',\n",
       " 'placed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'public',\n",
       " 'domain',\n",
       " 'shakespeare',\n",
       " 'this',\n",
       " 'etext',\n",
       " 'has',\n",
       " 'certain',\n",
       " 'copyright',\n",
       " 'implications',\n",
       " 'you',\n",
       " 'should',\n",
       " 'read',\n",
       " 'this',\n",
       " 'electronic',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'complete',\n",
       " 'works',\n",
       " 'of',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'is',\n",
       " 'copyright',\n",
       " '1990',\n",
       " '1993',\n",
       " 'by',\n",
       " 'world',\n",
       " 'library',\n",
       " 'inc',\n",
       " 'and',\n",
       " 'is',\n",
       " 'provided',\n",
       " 'by',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'etext',\n",
       " 'of',\n",
       " 'illinois',\n",
       " 'benedictine',\n",
       " 'college',\n",
       " 'with',\n",
       " 'permission',\n",
       " 'electronic',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'readable',\n",
       " 'copies',\n",
       " 'may',\n",
       " 'be',\n",
       " 'distributed',\n",
       " 'so',\n",
       " 'long',\n",
       " 'as',\n",
       " 'such',\n",
       " 'copies',\n",
       " '1',\n",
       " 'are',\n",
       " 'for',\n",
       " 'your',\n",
       " 'or',\n",
       " 'others',\n",
       " 'personal',\n",
       " 'use',\n",
       " 'only',\n",
       " 'and',\n",
       " '2',\n",
       " 'are',\n",
       " 'not',\n",
       " 'distributed',\n",
       " 'or',\n",
       " 'used',\n",
       " 'commercially',\n",
       " 'prohibited',\n",
       " 'commercial',\n",
       " 'distribution',\n",
       " 'includes',\n",
       " 'by',\n",
       " 'any',\n",
       " 'service',\n",
       " 'that',\n",
       " 'charges',\n",
       " 'for',\n",
       " 'download',\n",
       " 'time',\n",
       " 'or',\n",
       " 'for',\n",
       " 'membership',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'is',\n",
       " 'proud',\n",
       " 'to',\n",
       " 'cooperate',\n",
       " 'with',\n",
       " 'the',\n",
       " 'world',\n",
       " 'library',\n",
       " 'in',\n",
       " 'the',\n",
       " 'presentation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'complete',\n",
       " 'works',\n",
       " 'of',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'for',\n",
       " 'your',\n",
       " 'reading',\n",
       " 'for',\n",
       " 'education',\n",
       " 'and',\n",
       " 'entertainment',\n",
       " 'however',\n",
       " 'this',\n",
       " 'is',\n",
       " 'neither',\n",
       " 'shareware',\n",
       " 'nor',\n",
       " 'public',\n",
       " 'domain',\n",
       " 'and',\n",
       " 'under',\n",
       " 'the',\n",
       " 'library',\n",
       " 'of',\n",
       " 'the',\n",
       " 'future',\n",
       " 'conditions',\n",
       " 'of',\n",
       " 'this',\n",
       " 'presentation',\n",
       " 'no',\n",
       " 'charges',\n",
       " 'may',\n",
       " 'be',\n",
       " 'made',\n",
       " 'for',\n",
       " 'any',\n",
       " 'access',\n",
       " 'to',\n",
       " 'this',\n",
       " 'material',\n",
       " 'you',\n",
       " 'are',\n",
       " 'encouraged',\n",
       " 'to',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'to',\n",
       " 'anyone',\n",
       " 'you',\n",
       " 'like',\n",
       " 'but',\n",
       " 'no',\n",
       " 'charges',\n",
       " 'are',\n",
       " 'allowed',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'free',\n",
       " 'plain',\n",
       " 'vanilla',\n",
       " 'electronic',\n",
       " 'texts',\n",
       " 'etexts',\n",
       " 'readable',\n",
       " 'by',\n",
       " 'both',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'by',\n",
       " 'computers',\n",
       " 'since',\n",
       " '1971',\n",
       " 'these',\n",
       " 'etexts',\n",
       " 'prepared',\n",
       " 'by',\n",
       " 'hundreds',\n",
       " 'of',\n",
       " 'volunteers',\n",
       " 'and',\n",
       " 'donations',\n",
       " 'information',\n",
       " 'on',\n",
       " 'contacting',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'to',\n",
       " 'get',\n",
       " 'etexts',\n",
       " 'and',\n",
       " 'further',\n",
       " 'information',\n",
       " 'is',\n",
       " 'included',\n",
       " 'below',\n",
       " 'we',\n",
       " 'need',\n",
       " 'your',\n",
       " 'donations',\n",
       " 'the',\n",
       " 'complete',\n",
       " 'works',\n",
       " 'of',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'january',\n",
       " '1994',\n",
       " 'etext',\n",
       " '100',\n",
       " 'the',\n",
       " 'library',\n",
       " 'of',\n",
       " 'the',\n",
       " 'future',\n",
       " 'complete',\n",
       " 'works',\n",
       " 'of',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'library',\n",
       " 'of',\n",
       " 'the',\n",
       " 'future',\n",
       " 'is',\n",
       " 'a',\n",
       " 'trademark',\n",
       " 'tm',\n",
       " 'of',\n",
       " 'world',\n",
       " 'library',\n",
       " 'inc',\n",
       " 'this',\n",
       " 'file',\n",
       " 'should',\n",
       " 'be',\n",
       " 'named',\n",
       " 'shaks12',\n",
       " 'txt',\n",
       " 'or',\n",
       " 'shaks12',\n",
       " 'zip',\n",
       " 'corrected',\n",
       " 'editions',\n",
       " 'of',\n",
       " 'our',\n",
       " 'etexts',\n",
       " 'get',\n",
       " 'a',\n",
       " 'new',\n",
       " 'number',\n",
       " 'shaks13',\n",
       " 'txt',\n",
       " 'versions',\n",
       " 'based',\n",
       " 'on',\n",
       " 'separate',\n",
       " 'sources',\n",
       " 'get',\n",
       " 'new',\n",
       " 'letter',\n",
       " 'shaks10a',\n",
       " 'txt',\n",
       " 'if',\n",
       " 'you',\n",
       " 'would',\n",
       " 'like',\n",
       " 'further',\n",
       " 'information',\n",
       " 'about',\n",
       " 'world',\n",
       " 'library',\n",
       " 'inc',\n",
       " 'please',\n",
       " 'call',\n",
       " 'them',\n",
       " 'at',\n",
       " '1',\n",
       " '800',\n",
       " '443',\n",
       " '0238',\n",
       " 'or',\n",
       " 'email',\n",
       " 'julianc',\n",
       " 'netcom',\n",
       " 'com',\n",
       " 'please',\n",
       " 'give',\n",
       " 'them',\n",
       " 'our',\n",
       " 'thanks',\n",
       " 'for',\n",
       " 'their',\n",
       " 'shakespeare',\n",
       " 'cooperation',\n",
       " 'the',\n",
       " 'official',\n",
       " 'release',\n",
       " 'date',\n",
       " 'of',\n",
       " 'all',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'etexts',\n",
       " 'is',\n",
       " 'at',\n",
       " 'midnight',\n",
       " 'central',\n",
       " 'time',\n",
       " 'of',\n",
       " 'the',\n",
       " 'last',\n",
       " 'day',\n",
       " 'of',\n",
       " 'the',\n",
       " 'stated',\n",
       " 'month',\n",
       " 'a',\n",
       " 'preliminary',\n",
       " 'version',\n",
       " 'may',\n",
       " 'often',\n",
       " 'be',\n",
       " 'posted',\n",
       " 'for',\n",
       " 'suggestion',\n",
       " 'comment',\n",
       " 'and',\n",
       " 'editing',\n",
       " 'by',\n",
       " 'those',\n",
       " 'who',\n",
       " 'wish',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " 'to',\n",
       " 'be',\n",
       " 'sure',\n",
       " 'you',\n",
       " 'have',\n",
       " 'an',\n",
       " 'up',\n",
       " 'to',\n",
       " 'date',\n",
       " 'first',\n",
       " 'edition',\n",
       " 'xxxxx10x',\n",
       " 'xxx',\n",
       " 'please',\n",
       " 'check',\n",
       " 'file',\n",
       " 'sizes',\n",
       " 'in',\n",
       " 'the',\n",
       " 'first',\n",
       " 'week',\n",
       " 'of',\n",
       " 'the',\n",
       " 'next',\n",
       " 'month',\n",
       " 'since',\n",
       " 'our',\n",
       " 'ftp',\n",
       " 'program',\n",
       " 'has',\n",
       " 'a',\n",
       " 'bug',\n",
       " 'in',\n",
       " 'it',\n",
       " 'that',\n",
       " 'scrambles',\n",
       " 'the',\n",
       " 'date',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'fix',\n",
       " 'and',\n",
       " 'failed',\n",
       " 'a',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'file',\n",
       " 'size',\n",
       " 'will',\n",
       " 'have',\n",
       " 'to',\n",
       " 'do',\n",
       " 'but',\n",
       " 'we',\n",
       " 'will',\n",
       " 'try',\n",
       " 'to',\n",
       " 'see',\n",
       " 'a',\n",
       " 'new',\n",
       " 'copy',\n",
       " 'has',\n",
       " 'at',\n",
       " 'least',\n",
       " 'one',\n",
       " 'byte',\n",
       " 'more',\n",
       " 'or',\n",
       " 'less',\n",
       " 'information',\n",
       " 'about',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'one',\n",
       " 'page',\n",
       " 'we',\n",
       " 'produce',\n",
       " 'about',\n",
       " 'two',\n",
       " 'million',\n",
       " 'dollars',\n",
       " 'for',\n",
       " 'each',\n",
       " 'hour',\n",
       " 'we',\n",
       " 'work',\n",
       " 'the',\n",
       " 'fifty',\n",
       " 'hours',\n",
       " 'is',\n",
       " 'one',\n",
       " 'conservative',\n",
       " 'estimate',\n",
       " 'for',\n",
       " 'how',\n",
       " 'long',\n",
       " 'it',\n",
       " 'we',\n",
       " 'take',\n",
       " 'to',\n",
       " 'get',\n",
       " 'any',\n",
       " 'etext',\n",
       " 'selected',\n",
       " 'entered',\n",
       " 'proofread',\n",
       " 'edited',\n",
       " 'copyright',\n",
       " 'searched',\n",
       " 'and',\n",
       " 'analyzed',\n",
       " 'the',\n",
       " 'copyright',\n",
       " 'letters',\n",
       " 'written',\n",
       " 'etc',\n",
       " 'this',\n",
       " 'projected',\n",
       " 'audience',\n",
       " 'is',\n",
       " 'one',\n",
       " 'hundred',\n",
       " 'million',\n",
       " 'readers',\n",
       " 'if',\n",
       " 'our',\n",
       " 'value',\n",
       " 'per',\n",
       " 'text',\n",
       " 'is',\n",
       " 'nominally',\n",
       " 'estimated',\n",
       " 'at',\n",
       " 'one',\n",
       " 'dollar',\n",
       " 'then',\n",
       " 'we',\n",
       " 'produce',\n",
       " '2',\n",
       " 'million',\n",
       " 'dollars',\n",
       " 'per',\n",
       " 'hour',\n",
       " 'this',\n",
       " 'year',\n",
       " 'we',\n",
       " 'will',\n",
       " 'have',\n",
       " 'to',\n",
       " 'do',\n",
       " 'four',\n",
       " 'text',\n",
       " 'files',\n",
       " 'per',\n",
       " 'month',\n",
       " 'thus',\n",
       " 'upping',\n",
       " 'our',\n",
       " 'productivity',\n",
       " 'from',\n",
       " 'one',\n",
       " 'million',\n",
       " 'the',\n",
       " 'goal',\n",
       " 'of',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'is',\n",
       " 'to',\n",
       " 'give',\n",
       " 'away',\n",
       " 'one',\n",
       " 'trillion',\n",
       " 'etext',\n",
       " 'files',\n",
       " 'by',\n",
       " 'the',\n",
       " 'december',\n",
       " '31',\n",
       " '2001',\n",
       " '10',\n",
       " '000',\n",
       " 'x',\n",
       " '100',\n",
       " '000',\n",
       " '000',\n",
       " 'trillion',\n",
       " 'this',\n",
       " 'is',\n",
       " 'ten',\n",
       " 'thousand',\n",
       " 'titles',\n",
       " 'each',\n",
       " 'to',\n",
       " 'one',\n",
       " 'hundred',\n",
       " 'million',\n",
       " 'readers',\n",
       " 'which',\n",
       " 'is',\n",
       " '10',\n",
       " 'of',\n",
       " 'the',\n",
       " 'expected',\n",
       " 'number',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'users',\n",
       " 'by',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'the',\n",
       " 'year',\n",
       " '2001',\n",
       " 'we',\n",
       " 'need',\n",
       " 'your',\n",
       " 'donations',\n",
       " 'more',\n",
       " 'than',\n",
       " 'ever',\n",
       " 'all',\n",
       " 'donations',\n",
       " 'should',\n",
       " 'be',\n",
       " 'made',\n",
       " 'to',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'ibc',\n",
       " 'and',\n",
       " 'are',\n",
       " 'tax',\n",
       " 'deductible',\n",
       " 'to',\n",
       " 'the',\n",
       " 'extent',\n",
       " 'allowable',\n",
       " 'by',\n",
       " 'law',\n",
       " 'ibc',\n",
       " 'is',\n",
       " 'illinois',\n",
       " 'benedictine',\n",
       " 'college',\n",
       " 'subscriptions',\n",
       " 'to',\n",
       " 'our',\n",
       " 'paper',\n",
       " 'newsletter',\n",
       " 'go',\n",
       " 'to',\n",
       " 'ibc',\n",
       " 'too',\n",
       " 'for',\n",
       " 'these',\n",
       " 'and',\n",
       " 'other',\n",
       " 'matters',\n",
       " 'please',\n",
       " 'mail',\n",
       " 'to',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'p',\n",
       " 'o',\n",
       " 'box',\n",
       " '2782',\n",
       " 'champaign',\n",
       " 'il',\n",
       " '61825',\n",
       " 'when',\n",
       " 'all',\n",
       " 'other',\n",
       " 'email',\n",
       " 'fails',\n",
       " 'try',\n",
       " 'our',\n",
       " 'michael',\n",
       " 's',\n",
       " 'hart',\n",
       " 'executive',\n",
       " 'director',\n",
       " 'hart',\n",
       " 'vmd',\n",
       " 'cso',\n",
       " 'uiuc',\n",
       " 'edu',\n",
       " 'internet',\n",
       " 'hart',\n",
       " 'uiucvmd',\n",
       " 'bitnet',\n",
       " 'we',\n",
       " 'would',\n",
       " 'prefer',\n",
       " 'to',\n",
       " 'send',\n",
       " 'you',\n",
       " 'this',\n",
       " 'information',\n",
       " 'by',\n",
       " 'email',\n",
       " 'internet',\n",
       " 'bitnet',\n",
       " 'compuserve',\n",
       " 'attmail',\n",
       " 'or',\n",
       " 'mcimail',\n",
       " 'if',\n",
       " 'you',\n",
       " 'have',\n",
       " 'an',\n",
       " 'ftp',\n",
       " 'program',\n",
       " 'or',\n",
       " 'emulator',\n",
       " 'please',\n",
       " 'ftp',\n",
       " 'directly',\n",
       " 'to',\n",
       " 'the',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'archives',\n",
       " 'mac',\n",
       " 'users',\n",
       " 'do',\n",
       " 'not',\n",
       " 'point',\n",
       " 'and',\n",
       " 'click',\n",
       " 'type',\n",
       " 'ftp',\n",
       " 'mrcnext',\n",
       " 'cso',\n",
       " 'uiuc',\n",
       " 'edu',\n",
       " 'login',\n",
       " 'anonymous',\n",
       " 'password',\n",
       " 'your',\n",
       " 'login',\n",
       " 'cd',\n",
       " 'etext',\n",
       " 'etext91',\n",
       " 'or',\n",
       " 'cd',\n",
       " 'etext92',\n",
       " 'or',\n",
       " 'cd',\n",
       " 'etext93',\n",
       " 'for',\n",
       " 'new',\n",
       " 'books',\n",
       " 'now',\n",
       " 'also',\n",
       " 'in',\n",
       " 'cd',\n",
       " 'etext',\n",
       " 'etext93',\n",
       " 'or',\n",
       " 'cd',\n",
       " 'etext',\n",
       " 'articles',\n",
       " 'get',\n",
       " 'suggest',\n",
       " 'gut',\n",
       " 'for',\n",
       " 'more',\n",
       " 'information',\n",
       " 'dir',\n",
       " 'to',\n",
       " 'see',\n",
       " 'files',\n",
       " 'get',\n",
       " 'or',\n",
       " 'mget',\n",
       " 'to',\n",
       " 'get',\n",
       " 'files',\n",
       " 'set',\n",
       " 'bin',\n",
       " 'for',\n",
       " 'zip',\n",
       " 'files',\n",
       " 'get',\n",
       " '0index',\n",
       " 'gut',\n",
       " 'for',\n",
       " 'a',\n",
       " 'list',\n",
       " 'of',\n",
       " 'books',\n",
       " 'and',\n",
       " 'get',\n",
       " 'new',\n",
       " 'gut',\n",
       " 'for',\n",
       " 'general',\n",
       " 'information',\n",
       " 'and',\n",
       " 'mget',\n",
       " 'gut',\n",
       " 'for',\n",
       " 'newsletters',\n",
       " 'information',\n",
       " 'prepared',\n",
       " 'by',\n",
       " 'the',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'legal',\n",
       " 'advisor',\n",
       " 'small',\n",
       " 'print',\n",
       " 'for',\n",
       " 'complete',\n",
       " 'shakespeare',\n",
       " 'this',\n",
       " 'electronic',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'complete',\n",
       " 'works',\n",
       " 'of',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'is',\n",
       " 'copyright',\n",
       " '1990',\n",
       " '1993',\n",
       " 'by',\n",
       " 'world',\n",
       " 'library',\n",
       " 'inc',\n",
       " 'and',\n",
       " 'is',\n",
       " 'provided',\n",
       " 'by',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'etext',\n",
       " 'of',\n",
       " 'illinois',\n",
       " 'benedictine',\n",
       " 'college',\n",
       " 'with',\n",
       " 'permission',\n",
       " 'since',\n",
       " 'unlike',\n",
       " 'many',\n",
       " 'other',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'tm',\n",
       " 'etexts',\n",
       " 'this',\n",
       " 'etext',\n",
       " 'is',\n",
       " 'copyright',\n",
       " 'protected',\n",
       " 'and',\n",
       " 'since',\n",
       " 'the',\n",
       " 'materials',\n",
       " 'and',\n",
       " 'methods',\n",
       " 'you',\n",
       " 'use',\n",
       " 'will',\n",
       " 'effect',\n",
       " 'the',\n",
       " 'project',\n",
       " 's',\n",
       " 'reputation',\n",
       " 'your',\n",
       " 'right',\n",
       " 'to',\n",
       " 'copy',\n",
       " 'and',\n",
       " 'distribute',\n",
       " 'it',\n",
       " 'is',\n",
       " 'limited',\n",
       " 'by',\n",
       " 'the',\n",
       " 'copyright',\n",
       " 'and',\n",
       " 'other',\n",
       " 'laws',\n",
       " 'and',\n",
       " 'by',\n",
       " 'the',\n",
       " 'conditions',\n",
       " 'of',\n",
       " 'this',\n",
       " 'small',\n",
       " 'print',\n",
       " 'statement',\n",
       " '1',\n",
       " 'license',\n",
       " 'a',\n",
       " 'you',\n",
       " 'may',\n",
       " 'and',\n",
       " 'are',\n",
       " 'encouraged',\n",
       " 'to',\n",
       " 'distribute',\n",
       " 'electronic',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'readable',\n",
       " 'copies',\n",
       " 'of',\n",
       " 'this',\n",
       " 'etext',\n",
       " 'so',\n",
       " 'long',\n",
       " 'as',\n",
       " 'such',\n",
       " 'copies',\n",
       " '1',\n",
       " 'are',\n",
       " 'for',\n",
       " 'your',\n",
       " 'or',\n",
       " 'others',\n",
       " 'personal',\n",
       " 'use',\n",
       " 'only',\n",
       " 'and',\n",
       " '2',\n",
       " 'are',\n",
       " 'not',\n",
       " 'distributed',\n",
       " 'or',\n",
       " 'used',\n",
       " 'commercially',\n",
       " 'prohibited',\n",
       " 'commercial',\n",
       " 'distribution',\n",
       " 'includes',\n",
       " 'by',\n",
       " 'any',\n",
       " 'service',\n",
       " 'that',\n",
       " 'charges',\n",
       " 'for',\n",
       " 'download',\n",
       " 'time',\n",
       " 'or',\n",
       " 'for',\n",
       " 'membership',\n",
       " 'b',\n",
       " 'this',\n",
       " 'license',\n",
       " 'is',\n",
       " 'subject',\n",
       " 'to',\n",
       " 'the',\n",
       " 'conditions',\n",
       " 'that',\n",
       " 'you',\n",
       " 'honor',\n",
       " 'the',\n",
       " 'refund',\n",
       " 'and',\n",
       " 'replacement',\n",
       " 'provisions',\n",
       " 'of',\n",
       " 'this',\n",
       " 'small',\n",
       " 'print',\n",
       " 'statement',\n",
       " 'and',\n",
       " 'that',\n",
       " 'you',\n",
       " 'distribute',\n",
       " 'exact',\n",
       " 'copies',\n",
       " 'of',\n",
       " 'this',\n",
       " 'etext',\n",
       " 'including',\n",
       " 'this',\n",
       " 'small',\n",
       " 'print',\n",
       " 'statement',\n",
       " 'such',\n",
       " 'copies',\n",
       " 'can',\n",
       " 'be',\n",
       " 'compressed',\n",
       " 'or',\n",
       " 'any',\n",
       " 'proprietary',\n",
       " 'form',\n",
       " 'including',\n",
       " 'any',\n",
       " 'form',\n",
       " 'resulting',\n",
       " 'from',\n",
       " 'word',\n",
       " 'processing',\n",
       " 'or',\n",
       " 'hypertext',\n",
       " 'software',\n",
       " 'so',\n",
       " 'long',\n",
       " 'as',\n",
       " 'either',\n",
       " '1',\n",
       " 'the',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98e576dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23902 key values\n",
      "The count for the word 'thee' is 9784\n"
     ]
    }
   ],
   "source": [
    "word_count_dict = {}\n",
    "\n",
    "# counter counts the occurence of each word in word list so word_count_dict contains word counts\n",
    "word_count_dict = Counter(word_list)\n",
    "# gets number of words\n",
    "print(f\"There are {len(word_count_dict)} key values\")\n",
    "\n",
    "#gets the count for the word 'is' but returns 0 if not found\n",
    "print(f\"The count for the word 'is' is {word_count_dict.get('is', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab15f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Prob is 23902\n",
      "P('thee') is 0.0034\n",
      "3181\n"
     ]
    }
   ],
   "source": [
    "probs = {}\n",
    "total_words = sum(word_count_dict.values())\n",
    "\n",
    "for word, word_count in  word_count_dict.items():\n",
    "    word_prob = word_count/total_words\n",
    "    probs[word] = word_prob\n",
    "print(f\"Length of Prob is {len(probs)}\")\n",
    "\n",
    "\n",
    "print(f\"P('thee') is {probs['thee']:.4f}\")\n",
    "print(word_count_dict['thee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b5632cf-5f06-4993-b2da-a2c902d3fa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"I live in New York and work as a data scientist.\")\n",
    "for word in doc.ents:\n",
    "    print(word.text, word.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2388c46f-0612-4466-84bb-7d1de1d7b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word):\n",
    "    delete_list = []\n",
    "    split_list = []\n",
    "    split_list = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    delete_list = [L+R[1:] for L, R in split_list]\n",
    "    return delete_list\n",
    "\n",
    "def switch_letter(word):\n",
    "    switch_list = []\n",
    "    split_list = []\n",
    "    split_list = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    switch_list = [L + R[1] + R[0] + R[2:] for L, R in split_list if len(R) >= 2]\n",
    "    return switch_list\n",
    "\n",
    "def replace_letter(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_list = []\n",
    "    split_list = []\n",
    "    split_list = [(word[0:i], word[i:]) for i in range(len(word))]\n",
    "    switch_list = [L + letter + (R[1:] if len(R) > 1 else '') for L, R in split_list if R for letter in letters]\n",
    "    replace_set = set(replace_list)\n",
    "    replace_list = sorted(list(replace_set))\n",
    "    return replace_list\n",
    "\n",
    "def insert_letter(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_list = []\n",
    "    split_list = []\n",
    "    split_list = [(word[0:i], word[i:]) for i in range(len(word)+1)]\n",
    "    insert_list = [L + letter + R for L, R in split_list for letter in letters]\n",
    "    return insert_list\n",
    "\n",
    "def edit_one_letter(word, allow_switches=True):\n",
    "    edit_one_set = set()\n",
    "    edit_one_set.update(delete_letter(word))\n",
    "    if allow_switches: edit_one_set.update(switch_letter(word))\n",
    "    edit_one_set.update(replace_letter(word))\n",
    "    edit_one_set.update(insert_letter(word))\n",
    "    if word in edit_one_set: edit_one_set.remove(word)\n",
    "    return edit_one_set\n",
    "\n",
    "def edit_two_letter(word, allow_switches=True):\n",
    "    edit_two_set = set()\n",
    "    edit_one = edit_one_letter(word, allow_switches=True)\n",
    "    for word in edit_one:\n",
    "        if word:\n",
    "            edit_two = edit_one_letter(word, allow_switches=allow_switches)\n",
    "            edit_two_set.update(edit_two)\n",
    "    return edit_two_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f095802f-2954-4ece-9b75-734619632c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines function for spelling suggestions and takes parameters word, probs, vocab and n\n",
    "'''word: The input word for which we need spelling suggestions.\n",
    "probs: A dictionary containing the probability of each word in the vocabulary.\n",
    "vocab: A set of valid words (vocabulary).'''\n",
    "def get_spelling_suggestions(word, probs, vocab, n=3):\n",
    "    #stores potential word corrections\n",
    "    suggestions = []\n",
    "    #store the top n suggestions\n",
    "    top_n_suggestions = []\n",
    "    suggestions = list((word in vocab and word) or edit_one_letter(word).intersection(vocab)\n",
    "                       or edit_two_letter(word).intersection(vocab))\n",
    "\n",
    "    #creates a list of lists, where each sublist contains a suggestion and its\n",
    "    #corresponding probability from the probs dictionary.\n",
    "    top_n_suggestions = [[s, probs[s]] for s in list(suggestions)]\n",
    "    return top_n_suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea9eb4f4-a4f6-49e6-bb40-89b0643936de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "word - thi\n",
      "Potential Correction - 0: th, Probability = 0.001266\n",
      "Potential Correction - 1: thin, Probability = 0.000027\n",
      "Potential Correction - 2: ti, Probability = 0.000002\n",
      "Potential Correction - 3: this, Probability = 0.007374\n",
      " \n",
      "word - dyes\n",
      "Potential Correction - 0: dye, Probability = 0.000005\n",
      "Potential Correction - 1: yes, Probability = 0.000221\n",
      "Potential Correction - 2: des, Probability = 0.000003\n",
      " \n",
      "word - furthar\n",
      "Potential Correction - 0: furth, Probability = 0.000001\n",
      "Potential Correction - 1: further, Probability = 0.000204\n",
      " \n",
      "word - disdaain\n",
      "Potential Correction - 0: disdain, Probability = 0.000042\n",
      " \n",
      "word - tumtultous\n",
      "Potential Correction - 0: tumultuous, Probability = 0.000004\n",
      " \n",
      "word - dnce\n",
      "Potential Correction - 0: dance, Probability = 0.000077\n"
     ]
    }
   ],
   "source": [
    "my_words = ['thi', 'dyes', 'furthar', 'disdaain', 'tumtultous', 'dnce']\n",
    "tmp_corrections = []\n",
    "for word_c in my_words:\n",
    "    tmp_corrections.append(get_spelling_suggestions(word_c, probs, vocab, 3))\n",
    "\n",
    "for i, word in enumerate(my_words):\n",
    "    print(' ')\n",
    "    print(f'word - {my_words[i]}')\n",
    "    for j, word_prob in enumerate(tmp_corrections[i]):\n",
    "        print(f'Potential Correction - {j}: {word_prob[0]}, Probability = {word_prob[1]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e56df12-28d2-4213-80ba-d863f12045cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{csme: 'came', ratha: 'not', dys: 'day'}\n",
      "I came home so that as I would not participate in the the function the next day.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import contextualSpellCheck\n",
    "except:\n",
    "    ! pip install contextualSpellCheck\n",
    "    import contextualSpellCheck\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "except:\n",
    "    ! pip install contextualSpellCheck\n",
    "    import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "contextualSpellCheck.add_to_pipe(nlp)\n",
    "doc = nlp(\"I csme home so that as I would ratha participate in the the function the next dys.\")\n",
    "\n",
    "#shows the number of corrections in the input text\n",
    "print(len(doc._.suggestions_spellCheck))\n",
    "\n",
    "#This show the actual corrections made through mappping\n",
    "print(doc._.suggestions_spellCheck)\n",
    "\n",
    "#This displays the outcome after correction\n",
    "print(doc._.outcome_spellCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484d3c9-3237-4e17-8992-7f41b98941b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
